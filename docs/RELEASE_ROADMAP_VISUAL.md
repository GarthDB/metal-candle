# metal-candle Visual Roadmap

**Last Updated**: December 18, 2024

---

## ðŸ“Š Release Timeline

```
2024 Q4              2025 Q1                    2025 Q2                    2025 Q3
   â”‚                    â”‚                          â”‚                          â”‚
   â”œâ”€ v1.3.0 âœ…        â”œâ”€ v1.3.1                  â”œâ”€ v1.7.0                  â”œâ”€ v2.0.0
   â”‚  Dec 18           â”‚  Late Jan                â”‚  Late May                â”‚  Jul-Sep
   â”‚  â€¢ Streaming      â”‚  â€¢ ApplyAdapter          â”‚  â€¢ Flash Attention       â”‚  â€¢ Multi-GPU
   â”‚  â€¢ Adapters       â”‚  â€¢ Benchmarks            â”‚  â€¢ 32k context           â”‚  â€¢ 70B+ models
   â”‚                   â”‚                          â”‚                          â”‚
   â”‚                   â”œâ”€ v1.4.0                  â”‚                          â”‚
   â”‚                   â”‚  Late Feb                â”‚                          â”‚
   â”‚                   â”‚  â€¢ GGUF support          â”‚                          â”‚
   â”‚                   â”‚  â€¢ Quantized inference   â”‚                          â”‚
   â”‚                   â”‚                          â”‚                          â”‚
   â”‚                   â”œâ”€ v1.5.0                  â”‚                          â”‚
   â”‚                   â”‚  Late Mar                â”‚                          â”‚
   â”‚                   â”‚  â€¢ LLaMA/Mistral         â”‚                          â”‚
   â”‚                   â”‚  â€¢ Multi-arch            â”‚                          â”‚
   â”‚                   â”‚                          â”‚                          â”‚
   â”‚                   â””â”€ v1.6.0                  â”‚                          â”‚
   â”‚                      Late Apr                â”‚                          â”‚
   â”‚                      â€¢ Quantization          â”‚                          â”‚
   â”‚                      â€¢ GPTQ/AWQ              â”‚                          â”‚
   â”‚                                              â”‚                          â”‚
```

---

## ðŸŽ¯ Feature Matrix

| Feature | v1.3.0 | v1.3.1 | v1.4.0 | v1.5.0 | v1.6.0 | v1.7.0 | v2.0.0 |
|---------|:------:|:------:|:------:|:------:|:------:|:------:|:------:|
| **Streaming Inference** | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… |
| **Adapter Registry** | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… |
| **Hot-Swap Adapters** | ðŸ”¸ | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… |
| **Streaming Benchmarks** | â±ï¸ | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… |
| **GGUF Loading** | âŒ | âŒ | âœ… | âœ… | âœ… | âœ… | âœ… |
| **Quantized Inference** | âŒ | âŒ | âœ… | âœ… | âœ… | âœ… | âœ… |
| **LLaMA Architecture** | âŒ | âŒ | âŒ | âœ… | âœ… | âœ… | âœ… |
| **Mistral Architecture** | âŒ | âŒ | âŒ | âœ… | âœ… | âœ… | âœ… |
| **In-Memory Quantization** | âŒ | âŒ | âŒ | âŒ | âœ… | âœ… | âœ… |
| **GPTQ/AWQ** | âŒ | âŒ | âŒ | âŒ | âœ… | âœ… | âœ… |
| **Flash Attention** | âŒ | âŒ | âŒ | âŒ | âŒ | âœ… | âœ… |
| **32k+ Context** | âŒ | âŒ | âŒ | âŒ | âŒ | âœ… | âœ… |
| **Multi-GPU** | âŒ | âŒ | âŒ | âŒ | âŒ | âŒ | âœ… |

**Legend**: âœ… Complete | ðŸ”¸ Partial | â±ï¸ Expected | âŒ Not Available

---

## ðŸ—ï¸ Architecture Evolution

### Current (v1.3.0)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         metal-candle v1.3.0         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Streaming Inference (sync/async)  â”‚
â”‚ â€¢ LoRA Adapter Registry             â”‚
â”‚ â€¢ Qwen + BERT Models                â”‚
â”‚ â€¢ Safetensors Format                â”‚
â”‚ â€¢ Single GPU (Metal)                â”‚
â”‚ â€¢ fp16 Only                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### v1.4.0 (February 2025)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         metal-candle v1.4.0         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Streaming Inference âœ…            â”‚
â”‚ â€¢ Hot-Swap Adapters âœ…              â”‚
â”‚ â€¢ Qwen + BERT Models                â”‚
â”‚ â€¢ Safetensors + GGUF â­             â”‚
â”‚ â€¢ Single GPU (Metal)                â”‚
â”‚ â€¢ fp16 + Quantized (4/8-bit) â­     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### v1.5.0 (March 2025)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         metal-candle v1.5.0         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Streaming Inference âœ…            â”‚
â”‚ â€¢ Hot-Swap Adapters âœ…              â”‚
â”‚ â€¢ Qwen + BERT + LLaMA + Mistral â­  â”‚
â”‚ â€¢ Safetensors + GGUF âœ…             â”‚
â”‚ â€¢ Single GPU (Metal)                â”‚
â”‚ â€¢ fp16 + Quantized (4/8-bit) âœ…     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### v1.7.0 (May 2025)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         metal-candle v1.7.0         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Streaming Inference âœ…            â”‚
â”‚ â€¢ Hot-Swap Adapters âœ…              â”‚
â”‚ â€¢ Multi-Architecture âœ…             â”‚
â”‚ â€¢ Multiple Formats âœ…               â”‚
â”‚ â€¢ Flash Attention â­                â”‚
â”‚ â€¢ 32k+ Context â­                   â”‚
â”‚ â€¢ Single GPU (Metal)                â”‚
â”‚ â€¢ fp16 + Quantized âœ…               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### v2.0.0 (Q3 2025)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         metal-candle v2.0.0         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Streaming Inference âœ…            â”‚
â”‚ â€¢ Hot-Swap Adapters âœ…              â”‚
â”‚ â€¢ Multi-Architecture âœ…             â”‚
â”‚ â€¢ Multiple Formats âœ…               â”‚
â”‚ â€¢ Flash Attention âœ…                â”‚
â”‚ â€¢ 32k+ Context âœ…                   â”‚
â”‚ â€¢ Multi-GPU (2-4 GPUs) â­           â”‚
â”‚ â€¢ 70B+ Model Support â­             â”‚
â”‚ â€¢ fp16 + Quantized âœ…               â”‚
â”‚ â€¢ Production Deployment â­          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ“ˆ Performance Evolution

### Inference Speed (Tokens/Second)

```
500 tok/s â”¤
          â”‚                                           â•­â”€ v2.0.0 (Multi-GPU)
400 tok/s â”¤                       â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
          â”‚                   â•­â”€â”€â”€â•¯ v1.7.0 (Flash Attention)
300 tok/s â”¤               â•­â”€â”€â”€â•¯
          â”‚           â•­â”€â”€â”€â•¯ v1.4.0 (Quantized)
200 tok/s â”¤       â•­â”€â”€â”€â•¯
          â”‚   â•­â”€â”€â”€â•¯ v1.3.0 (Streaming)
100 tok/s â”¤â”€â”€â”€â•¯
          â”‚
          â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€>
          v1.3.0 v1.3.1 v1.4.0 v1.5.0 v1.6.0 v1.7.0 v2.0.0
```

### Memory Efficiency (GB for 7B Model)

```
14 GB â”¤â”€â”€â”€â•®
      â”‚   â”‚ v1.3.0 (fp16)
12 GB â”¤   â”‚
      â”‚   â”‚
10 GB â”¤   â•°â”€â”€â”€â•®
      â”‚       â”‚ v1.4.0 (int8)
 8 GB â”¤       â”‚
      â”‚       â•°â”€â”€â”€â”€â”€â”€â”€â•®
 6 GB â”¤               â”‚
      â”‚               â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•® v1.4.0 (int4)
 4 GB â”¤                                   â”‚
      â”‚                                   â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>
      â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€>
      v1.3.0     v1.4.0         v1.5.0         v1.6.0         v2.0.0
```

---

## ðŸŽ¯ Development Focus by Quarter

### Q4 2024 (âœ… Complete)
- **Foundation**: Core features and quality
- **v1.0-v1.2**: Training, inference, embeddings
- **v1.3.0**: Streaming and adapter management

### Q1 2025 (ðŸš§ In Progress)
- **Ecosystem**: Format compatibility and architecture support
- **v1.3.1**: Hot-swapping implementation
- **v1.4.0**: GGUF and quantization
- **v1.5.0**: Multi-architecture support

### Q2 2025 (ðŸ“‹ Planned)
- **Performance**: Advanced optimizations
- **v1.6.0**: Advanced quantization methods
- **v1.7.0**: Flash Attention

### Q3 2025 (ðŸ“‹ Planned)
- **Scale**: Multi-GPU and production features
- **v2.0.0**: Multi-GPU training and inference

---

## ðŸ”„ Feature Dependency Graph

```
                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                            â”‚  v1.3.0 Core â”‚
                            â”‚   Features   â”‚
                            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â–¼              â–¼              â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ v1.3.1  â”‚    â”‚ v1.4.0  â”‚    â”‚ v1.5.0  â”‚
              â”‚  Adapt  â”‚    â”‚  GGUF   â”‚    â”‚ LLaMA/  â”‚
              â”‚  Swap   â”‚    â”‚         â”‚    â”‚ Mistral â”‚
              â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
                   â”‚              â”‚              â”‚
                   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ v1.6.0  â”‚
                    â”‚  Quant  â”‚
                    â”‚ Methods â”‚
                    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
                         â”‚
                    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
                    â–¼         â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ v1.7.0  â”‚ â”‚ v2.0.0  â”‚
              â”‚  Flash  â”‚ â”‚  Multi  â”‚
              â”‚  Attn   â”‚ â”‚   GPU   â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸŽ“ Complexity & Effort Estimation

| Release | Complexity | Effort (Weeks) | Risk | Community Impact |
|---------|:----------:|:--------------:|:----:|:----------------:|
| v1.3.1  | ðŸŸ¢ Low | 2-3 | Low | Medium |
| v1.4.0  | ðŸŸ¡ Medium | 3-4 | Medium | ðŸ”¥ High |
| v1.5.0  | ðŸŸ¡ Medium | 3-4 | Medium | ðŸ”¥ High |
| v1.6.0  | ðŸŸ  High | 3-4 | Medium | Medium |
| v1.7.0  | ðŸ”´ Very High | 4-5 | High | ðŸ”¥ High |
| v2.0.0  | ðŸ”´ Very High | 8-12 | High | ðŸ”¥ðŸ”¥ Very High |

**Complexity Factors**: API changes, new dependencies, Metal kernel development, testing requirements

---

## ðŸ† Priority Matrix

```
High Impact â”‚
           â”‚      v1.4.0 â—         â— v2.0.0
           â”‚      (GGUF)          (Multi-GPU)
           â”‚                  
           â”‚                â— v1.7.0
           â”‚              (Flash Attn)
           â”‚         
           â”‚  v1.3.1 â—           â— v1.5.0
Low Impact â”‚  (Apply)         (LLaMA)
           â”‚              
           â”‚                  â— v1.6.0
           â”‚                  (Quant)
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>
           Low Effort      High Effort
```

**Strategy**: 
- Start with high-impact, low-effort (v1.3.1, v1.4.0)
- Build to high-impact, high-effort (v1.7.0, v2.0.0)
- Schedule medium-impact features around infrastructure needs

---

## ðŸ“Š Community Engagement Plan

### Issue Tracking
- Weekly triage of new issues
- Monthly roadmap reviews
- Quarterly feature voting

### Communication
- Release announcements (GitHub, Twitter, Reddit)
- Progress updates in discussions
- Benchmark results published
- Development blogs for major features

### Contribution
- Good first issues labeled
- Detailed contribution guides
- Code review within 1 week
- Regular contributor recognition

---

## ðŸŽ¯ Success Metrics Dashboard

### Code Quality Targets

```
Tests:       [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 195+  â†’ 300+ (v2.0)
Coverage:    [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  ] 80%+  â†’ 85%+ (v2.0)
Clippy:      [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 0 warnings (maintained)
Docs:        [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100% (maintained)
```

### Performance Targets (7B Model, M4 Max)

```
Adapter Swap:     [â–ˆâ–ˆ] 2.5ms        â†’ <2ms (v1.3.1)
GGUF Loading:     [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] TBD (v1.4.0)
Quantized Speed:  [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] TBD (v1.4.0)
Flash Attention:  [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] TBD (v1.7.0)
Multi-GPU Scale:  [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] TBD (v2.0.0)
```

### Community Metrics

```
GitHub Stars:     â­ Track growth
Contributors:     ðŸ‘¥ Welcome new contributors
Issues Closed:    âœ… <48h response time
Downloads:        ðŸ“¦ Monitor crates.io (post-publish)
```

---

## ðŸš€ Getting Started as Contributor

### For v1.3.1 (Immediate)
1. Review Issue #49 (ApplyAdapter)
2. Check CONTRIBUTING.md
3. Set up development environment
4. Pick a task from the issue

### For v1.4.0+ (Future)
1. Comment on GitHub issues with interest
2. Research GGUF/quantization/etc.
3. Propose implementation approach
4. Start with smaller PRs first

---

## ðŸ“š Resources

- **Main Roadmap**: [ROADMAP.md](../ROADMAP.md)
- **Next Steps**: [NEXT_STEPS.md](../NEXT_STEPS.md)
- **Project Board**: https://github.com/users/GarthDB/projects/3
- **Contributing**: [CONTRIBUTING.md](../CONTRIBUTING.md)

---

*This visual roadmap is updated quarterly. Last update: December 18, 2024*

